import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, ReLU, Softmax
from tensorflow.keras.models import Model
from sklearn.model_selection import train_test_split
import numpy as np

# Load CIFAR10 dataset as example
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
x = np.concatenate((x_train, x_test))
y = np.concatenate((y_train, y_test))

# Train/Val/Test split 80:10:10
x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2)
x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5)

# Normalize images
x_train, x_val, x_test = x_train/255.0, x_val/255.0, x_test/255.0

# Base model
base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(32,32,3), pooling='avg')
x = base_model.output
x = Dense(128, activation='relu')(x)
output = Dense(10, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=output)

# Compile
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train
model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=25, batch_size=32)

print("Evaluation:", model.evaluate(x_test, y_test))
